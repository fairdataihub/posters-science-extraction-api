services:
  poster-extraction:
    build:
      context: .
      dockerfile: Dockerfile
    image: poster-extraction:latest
    container_name: poster-extraction
    networks:
      - ollama-network
    # .env is created on the server from GitHub Secrets; compose substitutes ${VAR} from it
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - HF_TOKEN=${HF_TOKEN:-}
      - PORT=8000
      - HOST=0.0.0.0
      - DATABASE_URL=${DATABASE_URL}
      - BUNNY_PRIVATE_STORAGE=${BUNNY_PRIVATE_STORAGE}
      - BUNNY_PRIVATE_STORAGE_KEY=${BUNNY_PRIVATE_STORAGE_KEY}
      - BUNNY_PUBLIC_STORAGE=${BUNNY_PUBLIC_STORAGE:-}
      - BUNNY_PUBLIC_STORAGE_KEY=${BUNNY_PUBLIC_STORAGE_KEY:-}
      - POLL_INTERVAL_SECONDS=${POLL_INTERVAL_SECONDS:-30}
    # pin to GPU device 1 only
    gpus:
      - device_ids: ["1"]
    ports:
      - "${APP_PORT:-47362}:8000"
    volumes:
      # Persistent HuggingFace model cache
      - ${HF_CACHE:-~/.cache/huggingface}:/root/.cache/huggingface
    command: python api.py
    restart: ${RESTART_POLICY:-unless-stopped}
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s
networks:
  ollama-network:
    external: true
    name: ollama-network
